# æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–å®æˆ˜

## SQL æŸ¥è¯¢ä¼˜åŒ–

### ç´¢å¼•ä¼˜åŒ–ç­–ç•¥
```sql
-- åˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX idx_user_email_status ON users(email, status);

-- åˆ›å»ºéƒ¨åˆ†ç´¢å¼•
CREATE INDEX idx_orders_active ON orders(status) WHERE status = 'active';

-- æŸ¥çœ‹ç´¢å¼•ä½¿ç”¨æƒ…å†µ
EXPLAIN (ANALYZE, BUFFERS) 
SELECT * FROM users WHERE email = 'test@example.com';

-- ç´¢å¼•ä½¿ç”¨ç»Ÿè®¡
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan as index_scans,
    idx_tup_read as tuples_read,
    idx_tup_fetch as tuples_fetched
FROM pg_stat_user_indexes 
WHERE schemaname = 'public'
ORDER BY idx_scan DESC;
```

### æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§
```sql
-- é¿å… SELECT *
SELECT id, name, email FROM users WHERE status = 'active';

-- ä½¿ç”¨ EXISTS ä»£æ›¿ IN
SELECT * FROM orders o 
WHERE EXISTS (
    SELECT 1 FROM customers c 
    WHERE c.id = o.customer_id AND c.country = 'US'
);

-- åˆ†é¡µä¼˜åŒ–ï¼ˆæ¸¸æ ‡åˆ†é¡µï¼‰
SELECT * FROM products 
WHERE id > $last_id 
ORDER BY id 
LIMIT 20;

-- ä½¿ç”¨ CTE ä¼˜åŒ–å¤æ‚æŸ¥è¯¢
WITH ranked_products AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY category_id ORDER BY price) as rank
    FROM products
)
SELECT * FROM ranked_products WHERE rank <= 5;
```

### æ‰§è¡Œè®¡åˆ’åˆ†æ
```sql
-- è¯¦ç»†æ‰§è¡Œè®¡åˆ’
EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON)
SELECT u.name, COUNT(o.id) as order_count
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE u.created_at > '2023-01-01'
GROUP BY u.id, u.name
HAVING COUNT(o.id) > 5;

-- æŸ¥è¯¢ç»Ÿè®¡ä¿¡æ¯
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    rows,
    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
FROM pg_stat_statements 
ORDER BY total_time DESC 
LIMIT 10;
```

## æ•°æ®åº“è®¾è®¡ä¼˜åŒ–

### è§„èŒƒåŒ–ä¸åè§„èŒƒåŒ–
```sql
-- è§„èŒƒåŒ–è®¾è®¡ï¼ˆç¬¬ä¸‰èŒƒå¼ï¼‰
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE user_profiles (
    user_id INTEGER PRIMARY KEY REFERENCES users(id),
    first_name VARCHAR(100),
    last_name VARCHAR(100),
    date_of_birth DATE
);

-- åè§„èŒƒåŒ–è®¾è®¡ï¼ˆè¯»ä¼˜åŒ–ï¼‰
CREATE TABLE order_summary (
    user_id INTEGER,
    order_count INTEGER,
    total_amount DECIMAL(10,2),
    last_order_date TIMESTAMP,
    PRIMARY KEY (user_id)
);

-- ç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW sales_by_month AS
SELECT 
    DATE_TRUNC('month', order_date) as month,
    COUNT(*) as order_count,
    SUM(amount) as total_sales
FROM orders
GROUP BY DATE_TRUNC('month', order_date);

-- åˆ·æ–°ç‰©åŒ–è§†å›¾
REFRESH MATERIALIZED VIEW CONCURRENTLY sales_by_month;
```

### åˆ†åŒºè¡¨è®¾è®¡
```sql
-- æŒ‰æ—¶é—´èŒƒå›´åˆ†åŒº
CREATE TABLE logs (
    id SERIAL,
    log_time TIMESTAMP NOT NULL,
    message TEXT,
    level VARCHAR(10)
) PARTITION BY RANGE (log_time);

-- åˆ›å»ºå­åˆ†åŒº
CREATE TABLE logs_2024_01 PARTITION OF logs
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE logs_2024_02 PARTITION OF logs
FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');

-- ç´¢å¼•åˆ†åŒº
CREATE INDEX CONCURRENTLY idx_logs_time ON logs (log_time);
CREATE INDEX CONCURRENTLY idx_logs_level ON logs (level);
```

## è¿æ¥æ± ä¸é…ç½®ä¼˜åŒ–

### PostgreSQL é…ç½®ä¼˜åŒ–
```conf
# postgresql.conf
# å†…å­˜è®¾ç½®
shared_buffers = 4GB                    # 25% of total RAM
effective_cache_size = 12GB             # 75% of total RAM
work_mem = 64MB                         # ç”¨äºæ’åºå’Œå“ˆå¸Œæ“ä½œ
maintenance_work_mem = 1GB              # ç»´æŠ¤æ“ä½œå†…å­˜

# æ£€æŸ¥ç‚¹ä¼˜åŒ–
checkpoint_completion_target = 0.9      # æ£€æŸ¥ç‚¹å®Œæˆç›®æ ‡
wal_buffers = 16MB                      # WALç¼“å†²åŒº
max_wal_size = 2GB
min_wal_size = 1GB

# è¿æ¥è®¾ç½®
max_connections = 200
superuser_reserved_connections = 3

# æ—¥å¿—è®¾ç½®
log_min_duration_statement = 1000       # è®°å½•æ‰§è¡Œè¶…è¿‡1ç§’çš„æŸ¥è¯¢
log_connections = on
log_disconnections = on
```

### è¿æ¥æ± é…ç½® (PgBouncer)
```ini
# pgbouncer.ini
[databases]
mydb = host=localhost port=5432 dbname=mydb

[pgbouncer]
listen_port = 6432
listen_addr = *
auth_type = md5
auth_file = userlist.txt
pool_mode = transaction
max_client_conn = 1000
default_pool_size = 25
reserve_pool_size = 5
```

## ç¼“å­˜ç­–ç•¥

### Redis ç¼“å­˜è®¾è®¡
```python
import redis
import json
import hashlib

class DatabaseCache:
    def __init__(self):
        self.redis = redis.Redis(host='localhost', port=6379, db=0)
    
    def get_cache_key(self, query, params):
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_str = f"{query}:{json.dumps(params, sort_keys=True)}"
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def cached_query(self, query, params, ttl=3600):
        """ç¼“å­˜æŸ¥è¯¢ç»“æœ"""
        cache_key = self.get_cache_key(query, params)
        
        # å°è¯•ä»ç¼“å­˜è·å–
        cached = self.redis.get(cache_key)
        if cached:
            return json.loads(cached)
        
        # æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢
        result = self.execute_query(query, params)
        
        # å†™å…¥ç¼“å­˜
        self.redis.setex(cache_key, ttl, json.dumps(result))
        return result
    
    def invalidate_pattern(self, pattern):
        """æŒ‰æ¨¡å¼æ¸…é™¤ç¼“å­˜"""
        keys = self.redis.keys(pattern)
        if keys:
            self.redis.delete(*keys)
```

### å¤šçº§ç¼“å­˜æ¶æ„
```python
import time
from functools import wraps

class MultiLevelCache:
    def __init__(self):
        self.local_cache = {}
        self.redis_client = redis.Redis()
    
    def cached(self, ttl=300):
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # ç”Ÿæˆç¼“å­˜é”®
                cache_key = f"{func.__name__}:{args}:{kwargs}"
                
                # å°è¯•æœ¬åœ°ç¼“å­˜
                if cache_key in self.local_cache:
                    cached_data, expiry = self.local_cache[cache_key]
                    if time.time() < expiry:
                        return cached_data
                    else:
                        del self.local_cache[cache_key]
                
                # å°è¯• Redis ç¼“å­˜
                redis_data = self.redis_client.get(cache_key)
                if redis_data:
                    result = json.loads(redis_data)
                    # æ›´æ–°æœ¬åœ°ç¼“å­˜
                    self.local_cache[cache_key] = (
                        result, time.time() + min(60, ttl)
                    )
                    return result
                
                # æ‰§è¡Œå‡½æ•°
                result = func(*args, **kwargs)
                
                # å†™å…¥ç¼“å­˜
                self.redis_client.setex(
                    cache_key, ttl, json.dumps(result)
                )
                self.local_cache[cache_key] = (
                    result, time.time() + min(60, ttl)
                )
                
                return result
            return wrapper
        return decorator
```

## ç›‘æ§ä¸è¯Šæ–­

### æ€§èƒ½ç›‘æ§æŸ¥è¯¢
```sql
-- æŸ¥çœ‹é”ç­‰å¾…
SELECT 
    blocked_locks.pid AS blocked_pid,
    blocked_activity.usename AS blocked_user,
    blocking_locks.pid AS blocking_pid,
    blocking_activity.usename AS blocking_user,
    blocked_activity.query AS blocked_statement,
    blocking_activity.query AS current_statement_in_blocking_process
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity 
    ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks 
    ON blocking_locks.locktype = blocked_locks.locktype
    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database
    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page
    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple
    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid
    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid
    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid
    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid
    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid
    AND blocking_locks.pid != blocked_locks.pid
JOIN pg_catalog.pg_stat_activity blocking_activity 
    ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;

-- è¡¨å¤§å°å’Œç´¢å¼•å¤§å°
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as total_size,
    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - 
                   pg_relation_size(schemaname||'.'||tablename)) as index_size
FROM pg_tables
WHERE schemaname NOT IN ('information_schema', 'pg_catalog')
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

### è‡ªåŠ¨ç»´æŠ¤è„šæœ¬
```bash
#!/bin/bash
# æ•°æ®åº“ç»´æŠ¤è„šæœ¬

# å¤‡ä»½æ•°æ®åº“
pg_dump -h localhost -U postgres mydb | gzip > /backup/mydb_$(date +%Y%m%d).sql.gz

# æ¸…ç†æ—§å¤‡ä»½
find /backup -name "mydb_*.sql.gz" -mtime +7 -delete

# é‡æ–°ç´¢å¼•
psql -h localhost -U postgres -d mydb -c "REINDEX DATABASE mydb;"

# æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
psql -h localhost -U postgres -d mydb -c "ANALYZE;"

# æ¸…ç†è¿æ¥
psql -h localhost -U postgres -d mydb -c "
SELECT pg_terminate_backend(pid) 
FROM pg_stat_activity 
WHERE datname = 'mydb' 
AND pid <> pg_backend_pid() 
AND state = 'idle' 
AND state_change < now() - interval '1 hour';"
```

## ä¼˜åŒ–æ£€æŸ¥æ¸…å•

### æŸ¥è¯¢ä¼˜åŒ–
- [ ] é¿å… SELECT *ï¼Œåªé€‰æ‹©éœ€è¦çš„åˆ—
- [ ] ä½¿ç”¨åˆé€‚çš„ç´¢å¼•
- [ ] é¿å…åœ¨ WHERE å­å¥ä¸­ä½¿ç”¨å‡½æ•°
- [ ] ä½¿ç”¨ EXISTS ä»£æ›¿ IN
- [ ] ä¼˜åŒ– JOIN é¡ºåº

### æ•°æ®åº“è®¾è®¡
- [ ] é€‚å½“çš„è§„èŒƒåŒ–çº§åˆ«
- [ ] è€ƒè™‘åˆ†åŒºè¡¨
- [ ] ä½¿ç”¨åˆé€‚çš„æ•°æ®ç±»å‹
- [ ] è®¾ç½®å¤–é”®çº¦æŸ
- [ ] å®šæœŸç»´æŠ¤ï¼ˆVACUUM, ANALYZEï¼‰

### æ¶æ„ä¼˜åŒ–
- [ ] ä½¿ç”¨è¿æ¥æ± 
- [ ] å®ç°è¯»å†™åˆ†ç¦»
- [ ] ä½¿ç”¨ç¼“å­˜å±‚
- [ ] æ•°æ®åº“åˆ†ç‰‡
- [ ] ç›‘æ§å’Œå‘Šè­¦

> **ğŸ’¡ æ€§èƒ½ä¼˜åŒ–åŸåˆ™**ï¼š
> 1. æµ‹é‡è€Œä¸æ˜¯çŒœæµ‹ - ä½¿ç”¨ EXPLAIN ANALYZE
> 2. ç´¢å¼•ä¸æ˜¯ä¸‡èƒ½çš„ - æƒè¡¡è¯»å†™æ€§èƒ½
> 3. ç¼“å­˜æ˜¯é“¶å¼¹ - ä½†è¦æ³¨æ„ä¸€è‡´æ€§
> 4. åˆ†åŒºæé«˜ç®¡ç†æ€§ - ä½†ä¸ä¸€å®šæé«˜æ€§èƒ½
> 5. ç›‘æ§æ˜¯æŒç»­çš„è¿‡ç¨‹ - å»ºç«‹åŸºçº¿å¹¶è·Ÿè¸ªå˜åŒ–